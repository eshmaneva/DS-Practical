{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOEtgqoyEelv",
        "outputId": "bfa790c0-36fb-4b23-f24d-19f6cb2f743f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets==1.0.2 in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.3.5)\n",
            "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets==1.0.2) (1.21.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.0.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.0.2) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.21.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rouge_score) (3.2.5)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from rouge_score) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "#Preinstalling necessary libraries / specificated versions are necessary to avoid compatibility issues\n",
        "!pip install datasets==1.0.2\n",
        "!pip install transformers\n",
        "\n",
        "#!rm seq2seq_trainer.py\n",
        "#!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/seq2seq/seq2seq_trainer.py\n",
        "\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBxuHDCuFD9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c00281d1-fa06-42c6-9615-cc810dff43b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'seq2seq' already exists and is not an empty directory.\n",
            "Obtaining file:///content/seq2seq\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from seq2seq==0.1) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from seq2seq==0.1) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from seq2seq==0.1) (6.0)\n",
            "Requirement already satisfied: pyrouge in /usr/local/lib/python3.7/dist-packages (from seq2seq==0.1) (0.1.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->seq2seq==0.1) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->seq2seq==0.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->seq2seq==0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->seq2seq==0.1) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->seq2seq==0.1) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->seq2seq==0.1) (1.15.0)\n",
            "Installing collected packages: seq2seq\n",
            "  Attempting uninstall: seq2seq\n",
            "    Found existing installation: seq2seq 0.1\n",
            "    Can't uninstall 'seq2seq'. No files were found to uninstall.\n",
            "  Running setup.py develop for seq2seq\n",
            "Successfully installed seq2seq-0.1\n"
          ]
        }
      ],
      "source": [
        "import datasets\n",
        "import transformers\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "\n",
        "#Tokenizer\n",
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "#Encoder-Decoder Model\n",
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "#Installing seq2seq training library & class\n",
        "!git clone https://github.com/google/seq2seq.git\n",
        "!pip install -e seq2seq\n",
        "#import seq2seq\n",
        "\n",
        "#Training\n",
        "from transformers import Trainer, TrainingArguments, Seq2SeqTrainer\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLSdqxW2Xd_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f341e79-ca9b-4578-e53f-9ef17dd7dad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tY3szKuvFErn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "5f71de35-7eaa-43ef-e403-8e5c01fd5efd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
            "\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before 568454\n",
            "Data size: 568427\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Summary                                               Text\n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...\n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...\n",
              "4            Great taffy  Great taffy at a great price.  There was a wid..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c5a67871-d08a-4de4-938b-5d3d4a68bd4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c5a67871-d08a-4de4-938b-5d3d4a68bd4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c5a67871-d08a-4de4-938b-5d3d4a68bd4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c5a67871-d08a-4de4-938b-5d3d4a68bd4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/DS Practical/Reviews.csv\", engine=\"python\", error_bad_lines=False)\n",
        "df.drop(columns=['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator','HelpfulnessDenominator', 'Score', 'Time'],axis=1,inplace=True)\n",
        "print(\"Before\",len(df))\n",
        "df = df.dropna()\n",
        "print(\"Data size:\",len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzxldx_lINlg"
      },
      "outputs": [],
      "source": [
        "#Converting Pandas DataFrame into the 'dataset' librry \n",
        "from datasets import Dataset\n",
        "train_data=Dataset.from_pandas(df[:550000])\n",
        "val_data=Dataset.from_pandas(df[550000:555000])\n",
        "test_data=Dataset.from_pandas(df[556000:557000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua27p5DNIUud",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "209e05cd36d94cafb97b067db6698fd5",
            "1e10efda490b411a8c73eb25035b1513",
            "3cdac2e2340a4231b33e464f5def891f",
            "f1f73d3bd0564a3fae7ef1b1b7fe7497",
            "0f95e825d61d4e0abd2fee1318c43cdf",
            "609fc067840c4415b6aa2f3bdad7f58a",
            "84d047fb03b346098dae102efb37a983",
            "e31e4e607b9f40be98f56278bcac0fdf",
            "e5a379614318456a8cb4f674e71ab8e0",
            "ebe29f2199d9441b9aede74da758ba17",
            "df517c420d7b4e1d9194c7d536d2964f",
            "7bfcd717f8214187bec8b8ce69df3d85",
            "7e305e4b73fe49698e33ed0987a56340",
            "26d3cc1ef1ad42bc8c875db2475c7bcd",
            "c6ad2fa6c3f54287ba3937de8f0eb48d",
            "4f03fc607cd94fda8768b6527b20abbb",
            "92a8e98311ef4e3a869116bb8baa4b6f",
            "a9cc2584992144218d88d4ed05489c0d",
            "96037b53a9994760a9761f3342a3af93",
            "3676f0ce00dc4dc29daa34818ff77ee5",
            "46c86ab130334c92b01d985769693640",
            "bf93a8f523f2481d8589b214004899a5"
          ]
        },
        "outputId": "815eb8a8-fe1b-42b1-e78e-bdc96b8665ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2149 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "209e05cd36d94cafb97b067db6698fd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bfcd717f8214187bec8b8ce69df3d85"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Tokenizing the data\n",
        "from transformers import RobertaTokenizerFast\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "tokenizer.bos_token = tokenizer.cls_token\n",
        "tokenizer.eos_token = tokenizer.sep_token\n",
        "batch_size=256  #change to 16 for full training\n",
        "encoder_max_length=40\n",
        "decoder_max_length=6\n",
        "\n",
        "def process_data_to_model_inputs(batch):\n",
        "  inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=encoder_max_length)\n",
        "  outputs = tokenizer(batch[\"Summary\"], padding=\"max_length\", truncation=True, max_length=decoder_max_length)\n",
        "\n",
        "  batch[\"input_ids\"] = inputs.input_ids\n",
        "  batch[\"attention_mask\"] = inputs.attention_mask\n",
        "  batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "  batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "  batch[\"labels\"] = outputs.input_ids.copy()\n",
        "\n",
        "  #RoBERTa automatically shifts the labels, so, the labels correspond exactly to `decoder_input_ids` \n",
        "  #We have to make sure that the PAD token is ignored\n",
        "  batch[\"labels\"] = [[-100 if token == tokenizer.pad_token_id else token for token in labels] for labels in batch[\"labels\"]]\n",
        "\n",
        "  return batch\n",
        "\n",
        "#Processing training data\n",
        "train_data = train_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"Text\", \"Summary\"]\n",
        ")\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n",
        "#Processing validation data\n",
        "val_data = val_data.map(\n",
        "    process_data_to_model_inputs, \n",
        "    batched=True, \n",
        "    batch_size=batch_size, \n",
        "    remove_columns=[\"Text\", \"Summary\"]\n",
        ")\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx2JTv5MIncV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b94c42e-b992-427c-bd42-cecd13ba0e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.encoder.layer.7.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.8.crossattention.self.value.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.10.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.output.dense.weight', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.11.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.self.key.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.11.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.11.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.self.query.weight', 'roberta.encoder.layer.7.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.10.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.9.crossattention.self.query.bias', 'roberta.encoder.layer.7.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.self.value.weight', 'roberta.encoder.layer.8.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.6.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.key.bias', 'roberta.encoder.layer.8.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.value.weight', 'roberta.encoder.layer.7.crossattention.output.dense.weight', 'roberta.encoder.layer.8.crossattention.self.query.weight', 'roberta.encoder.layer.11.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.9.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.11.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.10.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.9.crossattention.self.query.weight', 'roberta.encoder.layer.6.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.7.crossattention.output.dense.bias', 'roberta.encoder.layer.7.crossattention.self.value.weight', 'roberta.encoder.layer.9.crossattention.output.dense.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.11.crossattention.self.query.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.9.crossattention.self.key.weight', 'roberta.encoder.layer.7.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.output.dense.weight', 'roberta.encoder.layer.10.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.6.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.6.crossattention.self.value.bias', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.6.crossattention.self.key.weight', 'roberta.encoder.layer.10.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.8.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.8.crossattention.output.dense.bias', 'roberta.encoder.layer.9.crossattention.self.key.bias', 'roberta.encoder.layer.11.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.6.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.10.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.8.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.query.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
          ]
        }
      ],
      "source": [
        "from transformers import EncoderDecoderModel\n",
        "\n",
        "# set encoder decoder tying to True\n",
        "roberta_shared = EncoderDecoderModel.from_encoder_decoder_pretrained(\"roberta-base\", \"roberta-base\", tie_encoder_decoder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "563xPofLIqi0"
      },
      "outputs": [],
      "source": [
        "#Set special tokens\n",
        "roberta_shared.config.decoder_start_token_id = tokenizer.bos_token_id                                             \n",
        "roberta_shared.config.eos_token_id = tokenizer.eos_token_id\n",
        "\n",
        "#Sensible parameters for beam search\n",
        "#Set decoding params     \n",
        "roberta_shared.config.pad_token_id = tokenizer.pad_token_id                          \n",
        "roberta_shared.config.max_length = 40\n",
        "roberta_shared.config.early_stopping = True\n",
        "roberta_shared.config.no_repeat_ngram_size = 3\n",
        "roberta_shared.config.length_penalty = 2.0\n",
        "roberta_shared.config.num_beams = 4\n",
        "roberta_shared.config.vocab_size = roberta_shared.config.encoder.vocab_size\n",
        "from transformers import TrainingArguments, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-9Jo9ShIvKV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "e93062aa-d679-4a52-a1f3-618077c3ddc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n@dataclass\\nclass Seq2SeqTrainingArguments(TrainingArguments):\\n    label_smoothing: Optional[float] = field(\\n        default=0.0, metadata={\"help\": \"The label smoothing epsilon to apply (if not zero).\"}\\n    )\\n    sortish_sampler: bool = field(default=False, metadata={\"help\": \"Whether to SortishSamler or not.\"})\\n    predict_with_generate: bool = field(\\n        default=False, metadata={\"help\": \"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"}\\n    )\\n    adafactor: bool = field(default=False, metadata={\"help\": \"whether to use adafactor\"})\\n    encoder_layerdrop: Optional[float] = field(\\n        default=None, metadata={\"help\": \"Encoder layer dropout probability. Goes into model.config.\"}\\n    )\\n    decoder_layerdrop: Optional[float] = field(\\n        default=None, metadata={\"help\": \"Decoder layer dropout probability. Goes into model.config.\"}\\n    )\\n    dropout: Optional[float] = field(default=None, metadata={\"help\": \"Dropout probability. Goes into model.config.\"})\\n    attention_dropout: Optional[float] = field(\\n        default=None, metadata={\"help\": \"Attention dropout probability. Goes into model.config.\"}\\n    )\\n    lr_scheduler: Optional[str] = field(\\n        default=\"linear\", metadata={\"help\": f\"Which lr scheduler to use.\"}\\n    )\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\"\"\"\n",
        "@dataclass\n",
        "class Seq2SeqTrainingArguments(TrainingArguments):\n",
        "    label_smoothing: Optional[float] = field(\n",
        "        default=0.0, metadata={\"help\": \"The label smoothing epsilon to apply (if not zero).\"}\n",
        "    )\n",
        "    sortish_sampler: bool = field(default=False, metadata={\"help\": \"Whether to SortishSamler or not.\"})\n",
        "    predict_with_generate: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to use generate to calculate generative metrics (ROUGE, BLEU).\"}\n",
        "    )\n",
        "    adafactor: bool = field(default=False, metadata={\"help\": \"whether to use adafactor\"})\n",
        "    encoder_layerdrop: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Encoder layer dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    decoder_layerdrop: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Decoder layer dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    dropout: Optional[float] = field(default=None, metadata={\"help\": \"Dropout probability. Goes into model.config.\"})\n",
        "    attention_dropout: Optional[float] = field(\n",
        "        default=None, metadata={\"help\": \"Attention dropout probability. Goes into model.config.\"}\n",
        "    )\n",
        "    lr_scheduler: Optional[str] = field(\n",
        "        default=\"linear\", metadata={\"help\": f\"Which lr scheduler to use.\"}\n",
        "    )\n",
        "\"\"\"  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxWlmH_TI6H1"
      },
      "outputs": [],
      "source": [
        "#Load rouge for validation\n",
        "rouge = datasets.load_metric(\"rouge\")\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels_ids = pred.label_ids\n",
        "    pred_ids = pred.predictions\n",
        "\n",
        "    #All unnecessary tokens are removed\n",
        "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
        "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
        "\n",
        "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
        "\n",
        "    return {\n",
        "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
        "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
        "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfCCrWNiI8_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c608f9-ceb5-4b97-dbd4-b4334d1f37b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/DS Practical/\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    predict_with_generate=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    logging_steps=2,  \n",
        "    save_steps=16, \n",
        "    eval_steps=500, \n",
        "    warmup_steps=500,  \n",
        "    max_steps=150, # delete for full training\n",
        "    overwrite_output_dir=True,\n",
        "    save_total_limit=1,\n",
        "    fp16=False,\n",
        ")\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=roberta_shared,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=val_data\n",
        ")\n",
        "#trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjTej0Gk-g1z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3bdc2ecd-c9e5-40a0-9958-32b3ebccc0b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following columns in the training set  don't have a corresponding argument in `EncoderDecoderModel.forward` and have been ignored: __index_level_0__. If __index_level_0__ are not expected by `EncoderDecoderModel.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 550000\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 256\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 150\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [150/150 30:01, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-16\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-16/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-16/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-48] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-32\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-32/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-32/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-16] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-48\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-48/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-48/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-32] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-64\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-64/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-64/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-48] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-80\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-80/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-80/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-64] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-96\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-96/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-96/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-80] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-112\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-112/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-112/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-96] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-128\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-128/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-128/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-112] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "Saving model checkpoint to /content/drive/MyDrive/DS Practical/checkpoint-144\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoint-144/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive/MyDrive/DS Practical/checkpoint-128] due to args.save_total_limit\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/encoder_decoder/modeling_encoder_decoder.py:530: FutureWarning: Version v4.12.0 introduces a better way to train encoder-decoder models by computing the loss inside the encoder-decoder framework rather than in the decoder itself. You may observe training discrepancies if fine-tuning a model trained with versions anterior to 4.12.0. The decoder_input_ids are now created based on the labels, no need to pass them yourself anymore.\n",
            "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=150, training_loss=7.210732371012369, metrics={'train_runtime': 1813.9587, 'train_samples_per_second': 21.169, 'train_steps_per_second': 0.083, 'total_flos': 1056668156928000.0, 'train_loss': 7.210732371012369, 'epoch': 0.07})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3DHdQ8jI93F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9bb0e45ed13416998b9cc469163fa6e",
            "e6533dc55e004878ba225ff826db83f0",
            "b6a8664f8eef4ffca89ce7d1419bda85",
            "c3322c10584a4df7bbcab1d3faead07f",
            "46ba5ffdbfc543ba886b795c693ca1e6",
            "fef314361bc94a53871d05de550694a7",
            "40a389e450e8406981ddf54cd5b488a7",
            "96d4117f94ff49038ac79289c8450140",
            "5be4348bf2cc4c65b1cd992c697932e4",
            "a698b3178e0748f0a1cc922cbdb9b4d3",
            "b2672f140a6341ca9fc9ccc1b955b4eb"
          ]
        },
        "outputId": "eaa361eb-6a34-4e48-ec4f-f837660d81e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/roberta-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/d3ccdbfeb9aaa747ef20432d4976c32ee3fa69663b379deb253ccfce2bb1fdc5.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/cafdecc90fcab17011e12ac813dd574b4b3fea39da6dd817813efa010262ff3f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/d53fc0fa09b8342651efd4073d75e19617b3e51287c2a535becda5808a8db287.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/roberta-base/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/roberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/733bade19e5f0ce98e6531021dd5180994bb2f7b8bd7e80c7968805834ba351e.35205c6cfc956461d8515139f0f8dd5d207a2f336c0c3a83b4bc8dca3518e37b\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"roberta-base\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"max_position_embeddings\": 514,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.18.0\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "Configuration saved in /content/drive/MyDrive/DS Practical/checkpoints/config.json\n",
            "Model weights saved in /content/drive/MyDrive/DS Practical/checkpoints/pytorch_model.bin\n",
            "loading configuration file /content/drive/MyDrive/DS Practical/checkpoints/config.json\n",
            "Model config EncoderDecoderConfig {\n",
            "  \"architectures\": [\n",
            "    \"EncoderDecoderModel\"\n",
            "  ],\n",
            "  \"decoder\": {\n",
            "    \"_name_or_path\": \"roberta-base\",\n",
            "    \"add_cross_attention\": true,\n",
            "    \"architectures\": [\n",
            "      \"RobertaForMaskedLM\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": true,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-05,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 514,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"roberta\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 1,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"early_stopping\": true,\n",
            "  \"encoder\": {\n",
            "    \"_name_or_path\": \"roberta-base\",\n",
            "    \"add_cross_attention\": false,\n",
            "    \"architectures\": [\n",
            "      \"RobertaForMaskedLM\"\n",
            "    ],\n",
            "    \"attention_probs_dropout_prob\": 0.1,\n",
            "    \"bad_words_ids\": null,\n",
            "    \"bos_token_id\": 0,\n",
            "    \"chunk_size_feed_forward\": 0,\n",
            "    \"classifier_dropout\": null,\n",
            "    \"cross_attention_hidden_size\": null,\n",
            "    \"decoder_start_token_id\": null,\n",
            "    \"diversity_penalty\": 0.0,\n",
            "    \"do_sample\": false,\n",
            "    \"early_stopping\": false,\n",
            "    \"encoder_no_repeat_ngram_size\": 0,\n",
            "    \"eos_token_id\": 2,\n",
            "    \"exponential_decay_length_penalty\": null,\n",
            "    \"finetuning_task\": null,\n",
            "    \"forced_bos_token_id\": null,\n",
            "    \"forced_eos_token_id\": null,\n",
            "    \"hidden_act\": \"gelu\",\n",
            "    \"hidden_dropout_prob\": 0.1,\n",
            "    \"hidden_size\": 768,\n",
            "    \"id2label\": {\n",
            "      \"0\": \"LABEL_0\",\n",
            "      \"1\": \"LABEL_1\"\n",
            "    },\n",
            "    \"initializer_range\": 0.02,\n",
            "    \"intermediate_size\": 3072,\n",
            "    \"is_decoder\": false,\n",
            "    \"is_encoder_decoder\": false,\n",
            "    \"label2id\": {\n",
            "      \"LABEL_0\": 0,\n",
            "      \"LABEL_1\": 1\n",
            "    },\n",
            "    \"layer_norm_eps\": 1e-05,\n",
            "    \"length_penalty\": 1.0,\n",
            "    \"max_length\": 20,\n",
            "    \"max_position_embeddings\": 514,\n",
            "    \"min_length\": 0,\n",
            "    \"model_type\": \"roberta\",\n",
            "    \"no_repeat_ngram_size\": 0,\n",
            "    \"num_attention_heads\": 12,\n",
            "    \"num_beam_groups\": 1,\n",
            "    \"num_beams\": 1,\n",
            "    \"num_hidden_layers\": 12,\n",
            "    \"num_return_sequences\": 1,\n",
            "    \"output_attentions\": false,\n",
            "    \"output_hidden_states\": false,\n",
            "    \"output_scores\": false,\n",
            "    \"pad_token_id\": 1,\n",
            "    \"position_embedding_type\": \"absolute\",\n",
            "    \"prefix\": null,\n",
            "    \"problem_type\": null,\n",
            "    \"pruned_heads\": {},\n",
            "    \"remove_invalid_values\": false,\n",
            "    \"repetition_penalty\": 1.0,\n",
            "    \"return_dict\": true,\n",
            "    \"return_dict_in_generate\": false,\n",
            "    \"sep_token_id\": null,\n",
            "    \"task_specific_params\": null,\n",
            "    \"temperature\": 1.0,\n",
            "    \"tie_encoder_decoder\": false,\n",
            "    \"tie_word_embeddings\": true,\n",
            "    \"tokenizer_class\": null,\n",
            "    \"top_k\": 50,\n",
            "    \"top_p\": 1.0,\n",
            "    \"torch_dtype\": null,\n",
            "    \"torchscript\": false,\n",
            "    \"transformers_version\": \"4.18.0\",\n",
            "    \"type_vocab_size\": 1,\n",
            "    \"typical_p\": 1.0,\n",
            "    \"use_bfloat16\": false,\n",
            "    \"use_cache\": true,\n",
            "    \"vocab_size\": 50265\n",
            "  },\n",
            "  \"eos_token_id\": 2,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"length_penalty\": 2.0,\n",
            "  \"max_length\": 40,\n",
            "  \"model_type\": \"encoder-decoder\",\n",
            "  \"no_repeat_ngram_size\": 3,\n",
            "  \"num_beams\": 4,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"tie_encoder_decoder\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": null,\n",
            "  \"vocab_size\": 50265\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/DS Practical/checkpoints/pytorch_model.bin\n",
            "The following encoder weights were not tied to the decoder ['roberta/pooler']\n",
            "All model checkpoint weights were used when initializing EncoderDecoderModel.\n",
            "\n",
            "All the weights of EncoderDecoderModel were initialized from the model checkpoint at /content/drive/MyDrive/DS Practical/checkpoints.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use EncoderDecoderModel for predictions without further training.\n",
            "The following encoder weights were not tied to the decoder ['roberta/pooler']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9bb0e45ed13416998b9cc469163fa6e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import datasets\n",
        "from transformers import BertTokenizer, EncoderDecoderModel\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
        "roberta_shared.save_pretrained(\"/content/drive/MyDrive/DS Practical/checkpoints\")\n",
        "\n",
        "model = EncoderDecoderModel.from_pretrained(\"/content/drive/MyDrive/DS Practical/checkpoints\")\n",
        "#model.to(\"cuda\")\n",
        "batch_size = 1024\n",
        "\n",
        "# map data correctly\n",
        "def generate_summary(batch):\n",
        "    # Tokenizer will automatically set [BOS] <text> [EOS]\n",
        "    # cut off at BERT max length 512\n",
        "    inputs = tokenizer(batch[\"Text\"], padding=\"max_length\", truncation=True, max_length=50, return_tensors=\"pt\")\n",
        "    input_ids = inputs.input_ids#.to(\"cuda\")\n",
        "    attention_mask = inputs.attention_mask#.to(\"cuda\")\n",
        "\n",
        "    outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # all special tokens including will be removed\n",
        "    output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    batch[\"pred\"] = output_str\n",
        "\n",
        "    return batch\n",
        "test_data = test_data.select(range(5000))\n",
        "\n",
        "results = test_data.map(generate_summary, batched=True, batch_size=batch_size, remove_columns=[\"Text\"])\n",
        "\n",
        "pred_str = results[\"pred\"]\n",
        "label_str = results[\"Summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLaHC3ifJED2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "9c9e6d2d-4a5c-4d86-e8bd-2a1f55ef6f97"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f25767740baa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROUGE 1 SCORE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROUGE 2 SCORE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rouge2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROUGE F SCORE: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrouge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreferences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rougeL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"rougeL\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rouge' is not defined"
          ]
        }
      ],
      "source": [
        "#1000\n",
        "print(\"ROUGE 1 SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge1\"])[\"rouge1\"].mid)\n",
        "print(\"ROUGE 2 SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n",
        "print(\"ROUGE F SCORE: \",rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rougeL\"])[\"rougeL\"].mid)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "  \"Roberta.ipynb\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "209e05cd36d94cafb97b067db6698fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e10efda490b411a8c73eb25035b1513",
              "IPY_MODEL_3cdac2e2340a4231b33e464f5def891f",
              "IPY_MODEL_f1f73d3bd0564a3fae7ef1b1b7fe7497"
            ],
            "layout": "IPY_MODEL_0f95e825d61d4e0abd2fee1318c43cdf"
          }
        },
        "1e10efda490b411a8c73eb25035b1513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609fc067840c4415b6aa2f3bdad7f58a",
            "placeholder": "",
            "style": "IPY_MODEL_84d047fb03b346098dae102efb37a983",
            "value": "100%"
          }
        },
        "3cdac2e2340a4231b33e464f5def891f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e31e4e607b9f40be98f56278bcac0fdf",
            "max": 2149,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5a379614318456a8cb4f674e71ab8e0",
            "value": 2149
          }
        },
        "f1f73d3bd0564a3fae7ef1b1b7fe7497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebe29f2199d9441b9aede74da758ba17",
            "placeholder": "",
            "style": "IPY_MODEL_df517c420d7b4e1d9194c7d536d2964f",
            "value": " 2149/2149 [01:41&lt;00:00, 22.35ba/s]"
          }
        },
        "0f95e825d61d4e0abd2fee1318c43cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609fc067840c4415b6aa2f3bdad7f58a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d047fb03b346098dae102efb37a983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e31e4e607b9f40be98f56278bcac0fdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a379614318456a8cb4f674e71ab8e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebe29f2199d9441b9aede74da758ba17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df517c420d7b4e1d9194c7d536d2964f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bfcd717f8214187bec8b8ce69df3d85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e305e4b73fe49698e33ed0987a56340",
              "IPY_MODEL_26d3cc1ef1ad42bc8c875db2475c7bcd",
              "IPY_MODEL_c6ad2fa6c3f54287ba3937de8f0eb48d"
            ],
            "layout": "IPY_MODEL_4f03fc607cd94fda8768b6527b20abbb"
          }
        },
        "7e305e4b73fe49698e33ed0987a56340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92a8e98311ef4e3a869116bb8baa4b6f",
            "placeholder": "",
            "style": "IPY_MODEL_a9cc2584992144218d88d4ed05489c0d",
            "value": "100%"
          }
        },
        "26d3cc1ef1ad42bc8c875db2475c7bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96037b53a9994760a9761f3342a3af93",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3676f0ce00dc4dc29daa34818ff77ee5",
            "value": 20
          }
        },
        "c6ad2fa6c3f54287ba3937de8f0eb48d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46c86ab130334c92b01d985769693640",
            "placeholder": "",
            "style": "IPY_MODEL_bf93a8f523f2481d8589b214004899a5",
            "value": " 20/20 [00:00&lt;00:00, 22.89ba/s]"
          }
        },
        "4f03fc607cd94fda8768b6527b20abbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a8e98311ef4e3a869116bb8baa4b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9cc2584992144218d88d4ed05489c0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96037b53a9994760a9761f3342a3af93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3676f0ce00dc4dc29daa34818ff77ee5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46c86ab130334c92b01d985769693640": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf93a8f523f2481d8589b214004899a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9bb0e45ed13416998b9cc469163fa6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6533dc55e004878ba225ff826db83f0",
              "IPY_MODEL_b6a8664f8eef4ffca89ce7d1419bda85",
              "IPY_MODEL_c3322c10584a4df7bbcab1d3faead07f"
            ],
            "layout": "IPY_MODEL_46ba5ffdbfc543ba886b795c693ca1e6"
          }
        },
        "e6533dc55e004878ba225ff826db83f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fef314361bc94a53871d05de550694a7",
            "placeholder": "",
            "style": "IPY_MODEL_40a389e450e8406981ddf54cd5b488a7",
            "value": "  0%"
          }
        },
        "b6a8664f8eef4ffca89ce7d1419bda85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d4117f94ff49038ac79289c8450140",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5be4348bf2cc4c65b1cd992c697932e4",
            "value": 0
          }
        },
        "c3322c10584a4df7bbcab1d3faead07f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a698b3178e0748f0a1cc922cbdb9b4d3",
            "placeholder": "",
            "style": "IPY_MODEL_b2672f140a6341ca9fc9ccc1b955b4eb",
            "value": " 0/5 [00:00&lt;?, ?ba/s]"
          }
        },
        "46ba5ffdbfc543ba886b795c693ca1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fef314361bc94a53871d05de550694a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40a389e450e8406981ddf54cd5b488a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96d4117f94ff49038ac79289c8450140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5be4348bf2cc4c65b1cd992c697932e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a698b3178e0748f0a1cc922cbdb9b4d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2672f140a6341ca9fc9ccc1b955b4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}